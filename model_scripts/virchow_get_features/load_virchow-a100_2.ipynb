{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc069fc1-8705-4a70-a23b-722c0c75c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import timm\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from timm.layers import SwiGLUPacked\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa982ab-49c7-4131-a5d2-27f42aa8483f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1\n"
     ]
    }
   ],
   "source": [
    "# for multi-gpu\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47a4b40c-16a1-4064-a696-70aa9bdeb1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\n",
    "    \"hf-hub:paige-ai/Virchow2\",\n",
    "    pretrained=True,\n",
    "    mlp_layer=SwiGLUPacked,\n",
    "    act_layer=torch.nn.SiLU\n",
    ")\n",
    "model.eval().cuda()\n",
    "\n",
    "config = resolve_data_config(model.pretrained_cfg, model=model)\n",
    "transform = create_transform(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95317b88-b12c-4d6d-b88a-c52d37ece4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TileFolderDataset(Dataset):\n",
    "    def __init__(self, folder):\n",
    "        self.paths = sorted([\n",
    "            os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(\".png\")\n",
    "        ])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
    "        return self.transform(img), self.paths[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "474f8e33-52c9-483f-95e4-8a8191363d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────── Embedding + Saving ─────────────\n",
    "def extract_and_save(tile_folder, h5_output_path, batch_size=96):\n",
    "    dataset = TileFolderDataset(tile_folder)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=20, pin_memory=True, prefetch_factor=2, persistent_workers=True)\n",
    "\n",
    "    all_embeddings = []\n",
    "    all_coords = []\n",
    "\n",
    "    for batch_imgs, batch_paths in tqdm(dataloader, desc=os.path.basename(tile_folder)):\n",
    "        batch_imgs = batch_imgs.cuda()\n",
    "        with torch.no_grad():\n",
    "            out = model(batch_imgs)  # shape: (B, 261, 1280)\n",
    "\n",
    "        cls = out[:, 0]\n",
    "        patch_tokens = out[:, 5:]  # skip register tokens\n",
    "        mean = patch_tokens.mean(dim=1)\n",
    "        embedding = torch.cat([cls, mean], dim=-1)  # (B, 2560)\n",
    "        all_embeddings.append(embedding.cpu())\n",
    "\n",
    "        # Extract x, y from filename (e.g., TCGA-XX_L1_1232_2048.png)\n",
    "        for path in batch_paths:\n",
    "            base = os.path.splitext(os.path.basename(path))[0]\n",
    "            try:\n",
    "                x, y = map(int, base.split(\"_\")[-2:])\n",
    "            except:\n",
    "                x, y = 0, 0\n",
    "            all_coords.append((x, y))\n",
    "\n",
    "    all_embeddings = torch.cat(all_embeddings, dim=0)     # (N, 2560)\n",
    "    all_coords = torch.tensor(all_coords)                 # (N, 2)\n",
    "\n",
    "    with h5py.File(h5_output_path, \"w\") as f:\n",
    "        f.create_dataset(\"features\", data=all_embeddings.numpy())\n",
    "        f.create_dataset(\"coords\", data=all_coords.numpy())\n",
    "\n",
    "    print(f\"✅ Saved {all_embeddings.shape[0]} embeddings to {h5_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7987e4f7-a8f5-40eb-aff9-047e9ea6576a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/orcd/data/edboyden/002/ezh/uni'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "444a8296-01eb-4848-a528-4d3d7199aba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: 0 NVIDIA A100 80GB PCIe\n"
     ]
    }
   ],
   "source": [
    "print(\"Using GPU:\", torch.cuda.current_device(), torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b366fbcb-f4fa-435e-ad92-13194b552e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed to process .ipynb_checkpoints: torch.cat(): expected a non-empty list of Tensors\n",
      "✅ Skipping TCGA-AA-3815, already exists.\n",
      "✅ Skipping TCGA-AA-3818, already exists.\n",
      "✅ Skipping TCGA-AA-3819, already exists.\n",
      "✅ Skipping TCGA-AA-3821, already exists.\n",
      "✅ Skipping TCGA-AA-3831, already exists.\n",
      "✅ Skipping TCGA-AA-3833, already exists.\n",
      "✅ Skipping TCGA-AA-3837, already exists.\n",
      "✅ Skipping TCGA-AA-3841, already exists.\n",
      "✅ Skipping TCGA-AA-3842, already exists.\n",
      "✅ Skipping TCGA-AA-3844, already exists.\n",
      "✅ Skipping TCGA-AA-3845, already exists.\n",
      "✅ Skipping TCGA-AA-3846, already exists.\n",
      "✅ Skipping TCGA-AA-3848, already exists.\n",
      "✅ Skipping TCGA-AA-3850, already exists.\n",
      "✅ Skipping TCGA-AA-3851, already exists.\n",
      "✅ Skipping TCGA-AA-3852, already exists.\n",
      "✅ Skipping TCGA-AA-3854, already exists.\n",
      "✅ Skipping TCGA-AA-3855, already exists.\n",
      "✅ Skipping TCGA-AA-3856, already exists.\n",
      "✅ Skipping TCGA-AA-3858, already exists.\n",
      "✅ Skipping TCGA-AA-3860, already exists.\n",
      "✅ Skipping TCGA-AA-3861, already exists.\n",
      "✅ Skipping TCGA-AA-3862, already exists.\n",
      "✅ Skipping TCGA-AA-3864, already exists.\n",
      "✅ Skipping TCGA-AA-3866, already exists.\n",
      "✅ Skipping TCGA-AA-3867, already exists.\n",
      "✅ Skipping TCGA-AA-3869, already exists.\n",
      "✅ Skipping TCGA-AA-3870, already exists.\n",
      "✅ Skipping TCGA-AA-3872, already exists.\n",
      "✅ Skipping TCGA-AA-3875, already exists.\n",
      "✅ Skipping TCGA-AA-3877, already exists.\n",
      "✅ Skipping TCGA-AA-3930, already exists.\n",
      "✅ Skipping TCGA-AA-3939, already exists.\n",
      "✅ Skipping TCGA-AA-3941, already exists.\n",
      "✅ Skipping TCGA-AA-3947, already exists.\n",
      "✅ Skipping TCGA-AA-3949, already exists.\n",
      "✅ Skipping TCGA-AA-3950, already exists.\n",
      "✅ Skipping TCGA-AA-3952, already exists.\n",
      "✅ Skipping TCGA-AA-3955, already exists.\n",
      "✅ Skipping TCGA-AA-3956, already exists.\n",
      "✅ Skipping TCGA-AA-3966, already exists.\n",
      "✅ Skipping TCGA-AA-3967, already exists.\n",
      "✅ Skipping TCGA-AA-3968, already exists.\n",
      "✅ Skipping TCGA-AA-3970, already exists.\n",
      "✅ Skipping TCGA-AA-3971, already exists.\n",
      "✅ Skipping TCGA-AA-3972, already exists.\n",
      "✅ Skipping TCGA-AA-3973, already exists.\n",
      "✅ Skipping TCGA-AA-3975, already exists.\n",
      "✅ Skipping TCGA-AA-3976, already exists.\n",
      "✅ Skipping TCGA-AA-3977, already exists.\n",
      "✅ Skipping TCGA-AA-3979, already exists.\n",
      "✅ Skipping TCGA-AA-3980, already exists.\n",
      "✅ Skipping TCGA-AA-3982, already exists.\n",
      "✅ Skipping TCGA-AA-3984, already exists.\n",
      "✅ Skipping TCGA-AA-3986, already exists.\n",
      "✅ Skipping TCGA-AA-3989, already exists.\n",
      "✅ Skipping TCGA-AA-3994, already exists.\n",
      "✅ Skipping TCGA-AA-A004, already exists.\n",
      "✅ Skipping TCGA-AA-A00A, already exists.\n",
      "✅ Skipping TCGA-AA-A00D, already exists.\n",
      "✅ Skipping TCGA-AA-A00E, already exists.\n",
      "✅ Skipping TCGA-AA-A00F, already exists.\n",
      "✅ Skipping TCGA-AA-A00J, already exists.\n",
      "✅ Skipping TCGA-AA-A00K, already exists.\n",
      "✅ Skipping TCGA-AA-A00L, already exists.\n",
      "✅ Skipping TCGA-AA-A00N, already exists.\n",
      "✅ Skipping TCGA-AA-A00O, already exists.\n",
      "✅ Skipping TCGA-AA-A00Q, already exists.\n",
      "✅ Skipping TCGA-AA-A00R, already exists.\n",
      "✅ Skipping TCGA-AA-A00U, already exists.\n",
      "✅ Skipping TCGA-AA-A00W, already exists.\n",
      "✅ Skipping TCGA-AA-A00Z, already exists.\n",
      "✅ Skipping TCGA-AA-A010, already exists.\n",
      "✅ Skipping TCGA-AA-A017, already exists.\n",
      "✅ Skipping TCGA-AA-A01C, already exists.\n",
      "✅ Skipping TCGA-AA-A01D, already exists.\n",
      "✅ Skipping TCGA-AA-A01F, already exists.\n",
      "✅ Skipping TCGA-AA-A01G, already exists.\n",
      "✅ Skipping TCGA-AA-A01I, already exists.\n",
      "✅ Skipping TCGA-AA-A01K, already exists.\n",
      "✅ Skipping TCGA-AA-A01P, already exists.\n",
      "✅ Skipping TCGA-AA-A01Q, already exists.\n",
      "✅ Skipping TCGA-AA-A01R, already exists.\n",
      "✅ Skipping TCGA-AA-A01S, already exists.\n",
      "✅ Skipping TCGA-AA-A01T, already exists.\n",
      "✅ Skipping TCGA-AA-A01V, already exists.\n",
      "✅ Skipping TCGA-AA-A01X, already exists.\n",
      "✅ Skipping TCGA-AA-A01Z, already exists.\n",
      "✅ Skipping TCGA-AA-A022, already exists.\n",
      "✅ Skipping TCGA-AA-A024, already exists.\n",
      "✅ Skipping TCGA-AA-A029, already exists.\n",
      "✅ Skipping TCGA-AA-A02E, already exists.\n",
      "✅ Skipping TCGA-AA-A02F, already exists.\n",
      "✅ Skipping TCGA-AA-A02H, already exists.\n",
      "✅ Skipping TCGA-AA-A02J, already exists.\n",
      "✅ Skipping TCGA-AA-A02K, already exists.\n",
      "✅ Skipping TCGA-AA-A02O, already exists.\n",
      "✅ Skipping TCGA-AA-A02R, already exists.\n",
      "✅ Skipping TCGA-AA-A02W, already exists.\n",
      "✅ Skipping TCGA-AA-A02Y, already exists.\n",
      "✅ Skipping TCGA-AA-A03F, already exists.\n",
      "✅ Skipping TCGA-AA-A03J, already exists.\n",
      "✅ Skipping TCGA-AD-5900, already exists.\n",
      "✅ Skipping TCGA-AD-6548, already exists.\n",
      "✅ Skipping TCGA-AD-6888, already exists.\n",
      "✅ Skipping TCGA-AD-6889, already exists.\n",
      "✅ Skipping TCGA-AD-6890, already exists.\n",
      "✅ Skipping TCGA-AD-6895, already exists.\n",
      "✅ Skipping TCGA-AD-6899, already exists.\n",
      "✅ Skipping TCGA-AD-6901, already exists.\n",
      "✅ Skipping TCGA-AD-6963, already exists.\n",
      "✅ Skipping TCGA-AD-6964, already exists.\n",
      "✅ Skipping TCGA-AD-6965, already exists.\n",
      "✅ Skipping TCGA-AD-A5EJ, already exists.\n",
      "✅ Skipping TCGA-AD-A5EK, already exists.\n",
      "✅ Skipping TCGA-AF-2687, already exists.\n",
      "✅ Skipping TCGA-AF-2690, already exists.\n",
      "✅ Skipping TCGA-AF-2693, already exists.\n",
      "✅ Skipping TCGA-AF-3911, already exists.\n",
      "✅ Skipping TCGA-AF-4110, already exists.\n",
      "✅ Skipping TCGA-AF-5654, already exists.\n",
      "✅ Skipping TCGA-AF-6136, already exists.\n",
      "✅ Skipping TCGA-AF-6655, already exists.\n",
      "✅ Skipping TCGA-AF-6672, already exists.\n",
      "✅ Skipping TCGA-AF-A56K, already exists.\n",
      "✅ Skipping TCGA-AF-A56L, already exists.\n",
      "✅ Skipping TCGA-AF-A56N, already exists.\n",
      "✅ Skipping TCGA-AG-3591, already exists.\n",
      "✅ Skipping TCGA-AG-3592, already exists.\n",
      "✅ Skipping TCGA-AG-3725, already exists.\n",
      "✅ Skipping TCGA-AG-3731, already exists.\n",
      "✅ Skipping TCGA-AG-3732, already exists.\n",
      "✅ Skipping TCGA-AG-3742, already exists.\n",
      "✅ Skipping TCGA-AG-3902, already exists.\n",
      "✅ Skipping TCGA-AG-4021, already exists.\n",
      "✅ Skipping TCGA-AG-4022, already exists.\n",
      "✅ Skipping TCGA-AH-6544, already exists.\n",
      "✅ Skipping TCGA-AH-6547, already exists.\n",
      "✅ Skipping TCGA-AH-6643, already exists.\n",
      "✅ Skipping TCGA-AH-6644, already exists.\n",
      "✅ Skipping TCGA-AH-6897, already exists.\n",
      "✅ Skipping TCGA-AH-6903, already exists.\n",
      "✅ Skipping TCGA-AM-5820, already exists.\n",
      "✅ Skipping TCGA-AM-5821, already exists.\n",
      "✅ Skipping TCGA-AU-3779, already exists.\n",
      "✅ Skipping TCGA-AU-6004, already exists.\n",
      "✅ Skipping TCGA-AY-4070, already exists.\n",
      "✅ Skipping TCGA-AY-4071, already exists.\n",
      "✅ Skipping TCGA-AY-5543, already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-AY-6196: 100%|█████████████████████████████████████████████████████| 42/42 [02:49<00:00,  4.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 8118 embeddings to virchow_features/TCGA-AY-6196.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-AY-6197: 100%|█████████████████████████████████████████████████████| 57/57 [03:51<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 11039 embeddings to virchow_features/TCGA-AY-6197.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-AY-6386: 100%|█████████████████████████████████████████████████████| 32/32 [02:08<00:00,  4.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 6090 embeddings to virchow_features/TCGA-AY-6386.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-AY-A54L: 100%|█████████████████████████████████████████████████████| 46/46 [03:06<00:00,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 8909 embeddings to virchow_features/TCGA-AY-A54L.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-AY-A69D: 100%|█████████████████████████████████████████████████████| 33/33 [02:13<00:00,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 6300 embeddings to virchow_features/TCGA-AY-A69D.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-AY-A71X: 100%|███████████████████████████████████████████████████| 102/102 [06:50<00:00,  4.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 19800 embeddings to virchow_features/TCGA-AY-A71X.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-AY-A8YK: 100%|█████████████████████████████████████████████████████| 32/32 [02:07<00:00,  3.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 6104 embeddings to virchow_features/TCGA-AY-A8YK.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-AZ-4308: 100%|█████████████████████████████████████████████████████| 42/42 [02:48<00:00,  4.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 8064 embeddings to virchow_features/TCGA-AZ-4308.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-AZ-4313: 100%|█████████████████████████████████████████████████████| 47/47 [03:08<00:00,  4.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 9030 embeddings to virchow_features/TCGA-AZ-4313.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-AZ-4315: 100%|█████████████████████████████████████████████████████| 54/54 [03:39<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 10500 embeddings to virchow_features/TCGA-AZ-4315.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-AZ-4614:  25%|█████████████▌                                       | 13/51 [00:55<02:33,  4.04s/it]"
     ]
    }
   ],
   "source": [
    "tile_root_dir = \"virchow_tiles_gpu1\"               # root directory containing subfolders for each WSI\n",
    "output_dir = \"virchow_features\"                   # where to save .h5 files\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for slide_folder in sorted(os.listdir(tile_root_dir)):\n",
    "    slide_path = os.path.join(tile_root_dir, slide_folder)\n",
    "    if not os.path.isdir(slide_path):\n",
    "        continue  # skip files\n",
    "\n",
    "    h5_output_path = os.path.join(output_dir, f\"{slide_folder}.h5\")\n",
    "\n",
    "    if os.path.exists(h5_output_path):\n",
    "        print(f\"✅ Skipping {slide_folder}, already exists.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        extract_and_save(slide_path, h5_output_path, batch_size=196)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to process {slide_folder}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfed7597-1917-4d1a-b964-3ca46734394c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLAM",
   "language": "python",
   "name": "clam_latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
