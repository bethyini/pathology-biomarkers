{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc069fc1-8705-4a70-a23b-722c0c75c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import timm\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from timm.layers import SwiGLUPacked\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47a4b40c-16a1-4064-a696-70aa9bdeb1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\n",
    "    \"hf-hub:paige-ai/Virchow2\",\n",
    "    pretrained=True,\n",
    "    mlp_layer=SwiGLUPacked,\n",
    "    act_layer=torch.nn.SiLU\n",
    ")\n",
    "model.eval().cuda()\n",
    "\n",
    "config = resolve_data_config(model.pretrained_cfg, model=model)\n",
    "transform = create_transform(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95317b88-b12c-4d6d-b88a-c52d37ece4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TileFolderDataset(Dataset):\n",
    "    def __init__(self, folder):\n",
    "        self.paths = sorted([\n",
    "            os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(\".png\")\n",
    "        ])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
    "        return self.transform(img), self.paths[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "474f8e33-52c9-483f-95e4-8a8191363d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────── Embedding + Saving ─────────────\n",
    "def extract_and_save(tile_folder, h5_output_path, batch_size=96):\n",
    "    dataset = TileFolderDataset(tile_folder)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=20, pin_memory=True, prefetch_factor=2, persistent_workers=True)\n",
    "\n",
    "    all_embeddings = []\n",
    "    all_coords = []\n",
    "\n",
    "    for batch_imgs, batch_paths in tqdm(dataloader, desc=os.path.basename(tile_folder)):\n",
    "        batch_imgs = batch_imgs.cuda()\n",
    "        with torch.no_grad():\n",
    "            out = model(batch_imgs)  # shape: (B, 261, 1280)\n",
    "\n",
    "        cls = out[:, 0]\n",
    "        patch_tokens = out[:, 5:]  # skip register tokens\n",
    "        mean = patch_tokens.mean(dim=1)\n",
    "        embedding = torch.cat([cls, mean], dim=-1)  # (B, 2560)\n",
    "        all_embeddings.append(embedding.cpu())\n",
    "\n",
    "        # Extract x, y from filename (e.g., TCGA-XX_L1_1232_2048.png)\n",
    "        for path in batch_paths:\n",
    "            base = os.path.splitext(os.path.basename(path))[0]\n",
    "            try:\n",
    "                x, y = map(int, base.split(\"_\")[-2:])\n",
    "            except:\n",
    "                x, y = 0, 0\n",
    "            all_coords.append((x, y))\n",
    "\n",
    "    all_embeddings = torch.cat(all_embeddings, dim=0)     # (N, 2560)\n",
    "    all_coords = torch.tensor(all_coords)                 # (N, 2)\n",
    "\n",
    "    with h5py.File(h5_output_path, \"w\") as f:\n",
    "        f.create_dataset(\"features\", data=all_embeddings.numpy())\n",
    "        f.create_dataset(\"coords\", data=all_coords.numpy())\n",
    "\n",
    "    print(f\"✅ Saved {all_embeddings.shape[0]} embeddings to {h5_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7987e4f7-a8f5-40eb-aff9-047e9ea6576a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/orcd/data/edboyden/002/ezh/uni'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f72b871-b6d8-4b88-a847-db2cc0d5789f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed to process .ipynb_checkpoints: torch.cat(): expected a non-empty list of Tensors\n",
      "✅ Skipping TCGA-5M-AAT4, already exists.\n",
      "✅ Skipping TCGA-5M-AAT5, already exists.\n",
      "✅ Skipping TCGA-5M-AAT6, already exists.\n",
      "✅ Skipping TCGA-5M-AATE, already exists.\n",
      "✅ Skipping TCGA-A6-2671, already exists.\n",
      "✅ Skipping TCGA-A6-2672, already exists.\n",
      "✅ Skipping TCGA-A6-2674, already exists.\n",
      "✅ Skipping TCGA-A6-2675, already exists.\n",
      "✅ Skipping TCGA-A6-2676, already exists.\n",
      "✅ Skipping TCGA-A6-2677, already exists.\n",
      "✅ Skipping TCGA-A6-2678, already exists.\n",
      "✅ Skipping TCGA-A6-2679, already exists.\n",
      "✅ Skipping TCGA-A6-2680, already exists.\n",
      "✅ Skipping TCGA-A6-2681, already exists.\n",
      "✅ Skipping TCGA-A6-2682, already exists.\n",
      "✅ Skipping TCGA-A6-2683, already exists.\n",
      "✅ Skipping TCGA-A6-2684, already exists.\n",
      "✅ Skipping TCGA-A6-2685, already exists.\n",
      "✅ Skipping TCGA-A6-2686, already exists.\n",
      "✅ Skipping TCGA-A6-3807, already exists.\n",
      "✅ Skipping TCGA-A6-3808, already exists.\n",
      "✅ Skipping TCGA-A6-3809, already exists.\n",
      "✅ Skipping TCGA-A6-3810, already exists.\n",
      "✅ Skipping TCGA-A6-4105, already exists.\n",
      "✅ Skipping TCGA-A6-4107, already exists.\n",
      "✅ Skipping TCGA-A6-5656, already exists.\n",
      "✅ Skipping TCGA-A6-5657, already exists.\n",
      "✅ Skipping TCGA-A6-5659, already exists.\n",
      "✅ Skipping TCGA-A6-5660, already exists.\n",
      "✅ Skipping TCGA-A6-5661, already exists.\n",
      "✅ Skipping TCGA-A6-5662, already exists.\n",
      "✅ Skipping TCGA-A6-5664, already exists.\n",
      "✅ Skipping TCGA-A6-5665, already exists.\n",
      "✅ Skipping TCGA-A6-5666, already exists.\n",
      "✅ Skipping TCGA-A6-5667, already exists.\n",
      "✅ Skipping TCGA-A6-6137, already exists.\n",
      "✅ Skipping TCGA-A6-6138, already exists.\n",
      "✅ Skipping TCGA-A6-6140, already exists.\n",
      "✅ Skipping TCGA-A6-6141, already exists.\n",
      "✅ Skipping TCGA-A6-6142, already exists.\n",
      "✅ Skipping TCGA-A6-6648, already exists.\n",
      "✅ Skipping TCGA-A6-6649, already exists.\n",
      "✅ Skipping TCGA-A6-6650, already exists.\n",
      "✅ Skipping TCGA-A6-6651, already exists.\n",
      "✅ Skipping TCGA-A6-6652, already exists.\n",
      "✅ Skipping TCGA-A6-6653, already exists.\n",
      "✅ Skipping TCGA-A6-6654, already exists.\n",
      "✅ Skipping TCGA-A6-A565, already exists.\n",
      "✅ Skipping TCGA-A6-A566, already exists.\n",
      "✅ Skipping TCGA-A6-A567, already exists.\n",
      "✅ Skipping TCGA-A6-A56B, already exists.\n",
      "✅ Skipping TCGA-A6-A5ZU, already exists.\n",
      "✅ Skipping TCGA-AA-3488, already exists.\n",
      "✅ Skipping TCGA-AA-3489, already exists.\n",
      "✅ Skipping TCGA-AA-3492, already exists.\n",
      "✅ Skipping TCGA-AA-3494, already exists.\n",
      "✅ Skipping TCGA-AA-3495, already exists.\n",
      "✅ Skipping TCGA-AA-3496, already exists.\n",
      "✅ Skipping TCGA-AA-3506, already exists.\n",
      "✅ Skipping TCGA-AA-3509, already exists.\n",
      "✅ Skipping TCGA-AA-3510, already exists.\n",
      "✅ Skipping TCGA-AA-3511, already exists.\n",
      "✅ Skipping TCGA-AA-3514, already exists.\n",
      "✅ Skipping TCGA-AA-3516, already exists.\n",
      "✅ Skipping TCGA-AA-3517, already exists.\n",
      "✅ Skipping TCGA-AA-3518, already exists.\n",
      "✅ Skipping TCGA-AA-3519, already exists.\n",
      "✅ Skipping TCGA-AA-3520, already exists.\n",
      "✅ Skipping TCGA-AA-3521, already exists.\n",
      "✅ Skipping TCGA-AA-3522, already exists.\n",
      "✅ Skipping TCGA-AA-3524, already exists.\n",
      "✅ Skipping TCGA-AA-3525, already exists.\n",
      "✅ Skipping TCGA-AA-3526, already exists.\n",
      "✅ Skipping TCGA-AA-3527, already exists.\n",
      "✅ Skipping TCGA-AA-3529, already exists.\n",
      "✅ Skipping TCGA-AA-3530, already exists.\n",
      "✅ Skipping TCGA-AA-3531, already exists.\n",
      "✅ Skipping TCGA-AA-3532, already exists.\n",
      "✅ Skipping TCGA-AA-3534, already exists.\n",
      "✅ Skipping TCGA-AA-3538, already exists.\n",
      "✅ Skipping TCGA-AA-3542, already exists.\n",
      "✅ Skipping TCGA-AA-3543, already exists.\n",
      "✅ Skipping TCGA-AA-3544, already exists.\n",
      "✅ Skipping TCGA-AA-3548, already exists.\n",
      "✅ Skipping TCGA-AA-3549, already exists.\n",
      "✅ Skipping TCGA-AA-3552, already exists.\n",
      "✅ Skipping TCGA-AA-3553, already exists.\n",
      "✅ Skipping TCGA-AA-3554, already exists.\n",
      "✅ Skipping TCGA-AA-3555, already exists.\n",
      "✅ Skipping TCGA-AA-3556, already exists.\n",
      "✅ Skipping TCGA-AA-3558, already exists.\n",
      "✅ Skipping TCGA-AA-3560, already exists.\n",
      "✅ Skipping TCGA-AA-3561, already exists.\n",
      "✅ Skipping TCGA-AA-3562, already exists.\n",
      "✅ Skipping TCGA-AA-3655, already exists.\n",
      "✅ Skipping TCGA-AA-3660, already exists.\n",
      "✅ Skipping TCGA-AA-3662, already exists.\n",
      "✅ Skipping TCGA-AA-3663, already exists.\n",
      "✅ Skipping TCGA-AA-3664, already exists.\n",
      "✅ Skipping TCGA-AA-3666, already exists.\n",
      "✅ Skipping TCGA-AA-3667, already exists.\n",
      "✅ Skipping TCGA-AA-3672, already exists.\n",
      "✅ Skipping TCGA-AA-3673, already exists.\n",
      "✅ Skipping TCGA-AA-3675, already exists.\n",
      "✅ Skipping TCGA-AA-3678, already exists.\n",
      "✅ Skipping TCGA-AA-3679, already exists.\n",
      "✅ Skipping TCGA-AA-3680, already exists.\n",
      "✅ Skipping TCGA-AA-3681, already exists.\n",
      "✅ Skipping TCGA-AA-3684, already exists.\n",
      "✅ Skipping TCGA-AA-3685, already exists.\n",
      "✅ Skipping TCGA-AA-3688, already exists.\n",
      "✅ Skipping TCGA-AA-3692, already exists.\n",
      "✅ Skipping TCGA-AA-3693, already exists.\n",
      "✅ Skipping TCGA-AA-3695, already exists.\n",
      "✅ Skipping TCGA-AA-3696, already exists.\n",
      "✅ Skipping TCGA-AA-3697, already exists.\n",
      "✅ Skipping TCGA-AA-3710, already exists.\n",
      "✅ Skipping TCGA-AA-3712, already exists.\n",
      "✅ Skipping TCGA-AA-3713, already exists.\n",
      "✅ Skipping TCGA-AA-3715, already exists.\n",
      "✅ Skipping TCGA-AA-3811, already exists.\n",
      "✅ Skipping TCGA-AA-3812, already exists.\n",
      "✅ Skipping TCGA-AA-3814, already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-G4-6317: 100%|███████████████████████████| 121/121 [08:38<00:00,  4.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 11570 embeddings to virchow_features/TCGA-G4-6317.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-G4-6320: 100%|█████████████████████████████| 98/98 [06:59<00:00,  4.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 9398 embeddings to virchow_features/TCGA-G4-6320.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-G4-6321: 100%|███████████████████████████| 125/125 [08:53<00:00,  4.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 11970 embeddings to virchow_features/TCGA-G4-6321.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-G4-6322: 100%|███████████████████████████| 112/112 [07:58<00:00,  4.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 10735 embeddings to virchow_features/TCGA-G4-6322.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-G4-6323: 100%|█████████████████████████████| 80/80 [05:39<00:00,  4.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 7616 embeddings to virchow_features/TCGA-G4-6323.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-G4-6586: 100%|███████████████████████████| 100/100 [07:08<00:00,  4.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 9600 embeddings to virchow_features/TCGA-G4-6586.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-G4-6588: 100%|███████████████████████████| 119/119 [08:25<00:00,  4.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 11340 embeddings to virchow_features/TCGA-G4-6588.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-G4-6625: 100%|█████████████████████████████| 48/48 [03:27<00:00,  4.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 4606 embeddings to virchow_features/TCGA-G4-6625.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-G4-6626: 100%|█████████████████████████████| 84/84 [05:58<00:00,  4.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 8030 embeddings to virchow_features/TCGA-G4-6626.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-G4-6627: 100%|███████████████████████████| 135/135 [09:34<00:00,  4.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 12920 embeddings to virchow_features/TCGA-G4-6627.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-G4-6628: 100%|███████████████████████████| 124/124 [08:50<00:00,  4.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 11904 embeddings to virchow_features/TCGA-G4-6628.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-G5-6233: 100%|███████████████████████████| 105/105 [07:30<00:00,  4.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 10080 embeddings to virchow_features/TCGA-G5-6233.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-G5-6235: 100%|███████████████████████████| 107/107 [07:36<00:00,  4.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 10260 embeddings to virchow_features/TCGA-G5-6235.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-G5-6572: 100%|███████████████████████████| 118/118 [08:24<00:00,  4.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 11328 embeddings to virchow_features/TCGA-G5-6572.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-G5-6641: 100%|█████████████████████████████| 75/75 [05:21<00:00,  4.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 7200 embeddings to virchow_features/TCGA-G5-6641.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-NH-A50T: 100%|███████████████████████████| 124/124 [08:48<00:00,  4.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 11900 embeddings to virchow_features/TCGA-NH-A50T.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-NH-A50U:  32%|█████████▍                   | 24/74 [01:44<03:32,  4.24s/it]"
     ]
    }
   ],
   "source": [
    "tile_root_dir = \"slow_virchow_tiles\"               # root directory containing subfolders for each WSI\n",
    "output_dir = \"virchow_features\"                   # where to save .h5 files\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for slide_folder in sorted(os.listdir(tile_root_dir)):\n",
    "    slide_path = os.path.join(tile_root_dir, slide_folder)\n",
    "    if not os.path.isdir(slide_path):\n",
    "        continue  # skip files\n",
    "\n",
    "    h5_output_path = os.path.join(output_dir, f\"{slide_folder}.h5\")\n",
    "\n",
    "    if os.path.exists(h5_output_path):\n",
    "        print(f\"✅ Skipping {slide_folder}, already exists.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        extract_and_save(slide_path, h5_output_path, batch_size=96)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to process {slide_folder}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uni-env)",
   "language": "python",
   "name": "uni-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
