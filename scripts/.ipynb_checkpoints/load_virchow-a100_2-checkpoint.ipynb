{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc069fc1-8705-4a70-a23b-722c0c75c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import timm\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from timm.layers import SwiGLUPacked\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa982ab-49c7-4131-a5d2-27f42aa8483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multi-gpu\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47a4b40c-16a1-4064-a696-70aa9bdeb1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\n",
    "    \"hf-hub:paige-ai/Virchow2\",\n",
    "    pretrained=True,\n",
    "    mlp_layer=SwiGLUPacked,\n",
    "    act_layer=torch.nn.SiLU\n",
    ")\n",
    "model.eval().cuda()\n",
    "\n",
    "config = resolve_data_config(model.pretrained_cfg, model=model)\n",
    "transform = create_transform(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95317b88-b12c-4d6d-b88a-c52d37ece4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TileFolderDataset(Dataset):\n",
    "    def __init__(self, folder):\n",
    "        self.paths = sorted([\n",
    "            os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(\".png\")\n",
    "        ])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
    "        return self.transform(img), self.paths[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "474f8e33-52c9-483f-95e4-8a8191363d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────── Embedding + Saving ─────────────\n",
    "def extract_and_save(tile_folder, h5_output_path, batch_size=96):\n",
    "    dataset = TileFolderDataset(tile_folder)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=20, pin_memory=True, prefetch_factor=2, persistent_workers=True)\n",
    "\n",
    "    all_embeddings = []\n",
    "    all_coords = []\n",
    "\n",
    "    for batch_imgs, batch_paths in tqdm(dataloader, desc=os.path.basename(tile_folder)):\n",
    "        batch_imgs = batch_imgs.cuda()\n",
    "        with torch.no_grad():\n",
    "            out = model(batch_imgs)  # shape: (B, 261, 1280)\n",
    "\n",
    "        cls = out[:, 0]\n",
    "        patch_tokens = out[:, 5:]  # skip register tokens\n",
    "        mean = patch_tokens.mean(dim=1)\n",
    "        embedding = torch.cat([cls, mean], dim=-1)  # (B, 2560)\n",
    "        all_embeddings.append(embedding.cpu())\n",
    "\n",
    "        # Extract x, y from filename (e.g., TCGA-XX_L1_1232_2048.png)\n",
    "        for path in batch_paths:\n",
    "            base = os.path.splitext(os.path.basename(path))[0]\n",
    "            try:\n",
    "                x, y = map(int, base.split(\"_\")[-2:])\n",
    "            except:\n",
    "                x, y = 0, 0\n",
    "            all_coords.append((x, y))\n",
    "\n",
    "    all_embeddings = torch.cat(all_embeddings, dim=0)     # (N, 2560)\n",
    "    all_coords = torch.tensor(all_coords)                 # (N, 2)\n",
    "\n",
    "    with h5py.File(h5_output_path, \"w\") as f:\n",
    "        f.create_dataset(\"features\", data=all_embeddings.numpy())\n",
    "        f.create_dataset(\"coords\", data=all_coords.numpy())\n",
    "\n",
    "    print(f\"✅ Saved {all_embeddings.shape[0]} embeddings to {h5_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7987e4f7-a8f5-40eb-aff9-047e9ea6576a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/orcd/data/edboyden/002/ezh/uni'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "444a8296-01eb-4848-a528-4d3d7199aba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: 0 NVIDIA A100 80GB PCIe\n"
     ]
    }
   ],
   "source": [
    "print(\"Using GPU:\", torch.cuda.current_device(), torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b366fbcb-f4fa-435e-ad92-13194b552e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed to process .ipynb_checkpoints: torch.cat(): expected a non-empty list of Tensors\n",
      "✅ Skipping TCGA-AA-3815, already exists.\n",
      "✅ Skipping TCGA-AA-3818, already exists.\n",
      "✅ Skipping TCGA-AA-3819, already exists.\n",
      "✅ Skipping TCGA-AA-3821, already exists.\n",
      "✅ Skipping TCGA-AA-3831, already exists.\n",
      "✅ Skipping TCGA-AA-3833, already exists.\n",
      "✅ Skipping TCGA-AA-3837, already exists.\n",
      "✅ Skipping TCGA-AA-3841, already exists.\n",
      "✅ Skipping TCGA-AA-3842, already exists.\n",
      "✅ Skipping TCGA-AA-3844, already exists.\n",
      "✅ Skipping TCGA-AA-3845, already exists.\n",
      "✅ Skipping TCGA-AA-3846, already exists.\n",
      "✅ Skipping TCGA-AA-3848, already exists.\n",
      "✅ Skipping TCGA-AA-3850, already exists.\n",
      "✅ Skipping TCGA-AA-3851, already exists.\n",
      "✅ Skipping TCGA-AA-3852, already exists.\n",
      "✅ Skipping TCGA-AA-3854, already exists.\n",
      "✅ Skipping TCGA-AA-3855, already exists.\n",
      "✅ Skipping TCGA-AA-3856, already exists.\n",
      "✅ Skipping TCGA-AA-3858, already exists.\n",
      "✅ Skipping TCGA-AA-3860, already exists.\n",
      "✅ Skipping TCGA-AA-3861, already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCGA-AA-3862:   2%|▋                                | 1/45 [00:06<04:37,  6.31s/it]"
     ]
    }
   ],
   "source": [
    "tile_root_dir = \"virchow_tiles_gpu1\"               # root directory containing subfolders for each WSI\n",
    "output_dir = \"virchow_features\"                   # where to save .h5 files\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for slide_folder in sorted(os.listdir(tile_root_dir)):\n",
    "    slide_path = os.path.join(tile_root_dir, slide_folder)\n",
    "    if not os.path.isdir(slide_path):\n",
    "        continue  # skip files\n",
    "\n",
    "    h5_output_path = os.path.join(output_dir, f\"{slide_folder}.h5\")\n",
    "\n",
    "    if os.path.exists(h5_output_path):\n",
    "        print(f\"✅ Skipping {slide_folder}, already exists.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        extract_and_save(slide_path, h5_output_path, batch_size=196)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to process {slide_folder}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLAM",
   "language": "python",
   "name": "clam_latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
